// backend/neuroscript_compiler.rs

use std::collections::HashMap;

#[derive(Debug, Clone)]
pub enum Token {
    Identifier(String),
    Number(f64),
    StringLiteral(String),
    Keyword(String),
    Symbol(char),
    Eof,
}

pub struct Lexer {
    source: Vec<char>,
    position: usize,
}

impl Lexer {
    pub fn new(input: &str) -> Self {
        Self {
            source: input.chars().collect(),
            position: 0,
        }
    }

    fn peek(&self) -> Option<char> {
        self.source.get(self.position).copied()
    }

    fn advance(&mut self) -> Option<char> {
        let ch = self.peek();
        if ch.is_some() {
            self.position += 1;
        }
        ch
    }

    pub fn next_token(&mut self) -> Token {
        self.skip_whitespace();

        if let Some(ch) = self.peek() {
            if ch.is_alphabetic() || ch == '_' {
                return self.read_identifier_or_keyword();
            } else if ch.is_numeric() {
                return self.read_number();
            } else if ch == '"' {
                return self.read_string();
            } else if is_symbol(ch) {
                self.advance();
                return Token::Symbol(ch);
            }
        }
        Token::Eof
    }

    fn skip_whitespace(&mut self) {
        while let Some(ch) = self.peek() {
            if ch.is_whitespace() {
                self.advance();
            } else {
                break;
            }
        }
    }

    fn read_identifier_or_keyword(&mut self) -> Token {
        let mut ident = String::new();
        while let Some(ch) = self.peek() {
            if ch.is_alphanumeric() || ch == '_' {
                ident.push(ch);
                self.advance();
            } else {
                break;
            }
        }
        if is_keyword(&ident) {
            Token::Keyword(ident)
        } else {
            Token::Identifier(ident)
        }
    }

    fn read_number(&mut self) -> Token {
        let mut num_str = String::new();
        while let Some(ch) = self.peek() {
            if ch.is_numeric() || ch == '.' {
                num_str.push(ch);
                self.advance();
            } else {
                break;
            }
        }
        let number = num_str.parse::<f64>().unwrap_or(0.0);
        Token::Number(number)
    }

    fn read_string(&mut self) -> Token {
        self.advance(); // skip opening quote
        let mut string = String::new();
        while let Some(ch) = self.peek() {
            if ch == '"' {
                self.advance();
                break;
            } else {
                string.push(ch);
                self.advance();
            }
        }
        Token::StringLiteral(string)
    }
}

fn is_keyword(s: &str) -> bool {
    matches!(s, "start" | "filter" | "send" | "to" | "if" | "else" | "loop" | "fn" | "return")
}

fn is_symbol(ch: char) -> bool {
    matches!(ch, '(' | ')' | '{' | '}' | ',' | ';' | '=' | '+' | '-' | '*' | '/' | '<' | '>' | '!')
}

#[derive(Debug)]
pub enum AstNode {
    Program(Vec<AstNode>),
    FunctionDecl { name: String, params: Vec<String>, body: Vec<AstNode> },
    Call { name: String, args: Vec<AstNode> },
    If { condition: Box<AstNode>, then_branch: Vec<AstNode>, else_branch: Option<Vec<AstNode>> },
    Return(Box<AstNode>),
    Identifier(String),
    Number(f64),
    StringLiteral(String),
    BinaryOp { left: Box<AstNode>, op: char, right: Box<AstNode> },
}

pub struct Parser<'a> {
    lexer: &'a mut Lexer,
    current_token: Token,
}

impl<'a> Parser<'a> {
    pub fn new(lexer: &'a mut Lexer) -> Self {
        let current_token = lexer.next_token();
        Self { lexer, current_token }
    }

    fn eat(&mut self, expected: &Token) -> bool {
        if std::mem::discriminant(&self.current_token) == std::mem::discriminant(expected) {
            self.current_token = self.lexer.next_token();
            true
        } else {
            false
        }
    }

    pub fn parse_program(&mut self) -> AstNode {
        let mut statements = Vec::new();
        while self.current_token != Token::Eof {
            if let Some(stmt) = self.parse_statement() {
                statements.push(stmt);
            }
        }
        AstNode::Program(statements)
    }

    fn parse_statement(&mut self) -> Option<AstNode> {
        match &self.current_token {
            Token::Keyword(k) if k == "start" => self.parse_start_command(),
            Token::Keyword(k) if k == "filter" => self.parse_filter_command(),
            Token::Keyword(k) if k == "send" => self.parse_send_command(),
            _ => {
                self.current_token = self.lexer.next_token();
                None
            }
        }
    }

    fn parse_start_command(&mut self) -> Option<AstNode> {
        // start app "photo-organizer"
        self.eat(&Token::Keyword("start".to_string()));
        if let Token::Identifier(app_name) = &self.current_token {
            let name = app_name.clone();
            self.eat(&Token::Identifier(app_name.clone()));
            Some(AstNode::Call { name: "start".to_string(), args: vec![AstNode::Identifier(name)] })
        } else if let Token::StringLiteral(app_name) = &self.current_token {
            let name = app_name.clone();
            self.eat(&Token::StringLiteral(app_name.clone()));
            Some(AstNode::Call { name: "start".to_string(), args: vec![AstNode::StringLiteral(name)] })
        } else {
            None
        }
    }

    fn parse_filter_command(&mut self) -> Option<AstNode> {
        // filter all images with blurred faces
        self.eat(&Token::Keyword("filter".to_string()));
        let mut args = Vec::new();

        // simplistic: consume tokens until end or next keyword
        while let Token::Identifier(_) | Token::Keyword(_) | Token::StringLiteral(_) = &self.current_token {
            match &self.current_token {
                Token::Identifier(s) | Token::Keyword(s) => {
                    args.push(AstNode::Identifier(s.clone()));
                }
                Token::StringLiteral(s) => {
                    args.push(AstNode::StringLiteral(s.clone()));
                }
                _ => {}
            }
            self.current_token = self.lexer.next_token();
        }
        Some(AstNode::Call { name: "filter".to_string(), args })
    }

    fn parse_send_command(&mut self) -> Option<AstNode> {
        // send results to private gallery called "memories"
        self.eat(&Token::Keyword("send".to_string()));
        let mut args = Vec::new();

        while let Token::Identifier(_) | Token::Keyword(_) | Token::StringLiteral(_) = &self.current_token {
            match &self.current_token {
                Token::Identifier(s) | Token::Keyword(s) => {
                    args.push(AstNode::Identifier(s.clone()));
                }
                Token::StringLiteral(s) => {
                    args.push(AstNode::StringLiteral(s.clone()));
                }
                _ => {}
            }
            self.current_token = self.lexer.next_token();
        }
        Some(AstNode::Call { name: "send".to_string(), args })
    }
}

pub struct Compiler {
    pub symbol_table: HashMap<String, usize>,
}

impl Compiler {
    pub fn new() -> Self {
        Self {
            symbol_table: HashMap::new(),
        }
    }

    pub fn compile(&mut self, ast: &AstNode) -> Vec<u8> {
        let mut bytecode = Vec::new();
        self.compile_node(ast, &mut bytecode);
        bytecode
    }

    fn compile_node(&mut self, node: &AstNode, output: &mut Vec<u8>) {
        match node {
            AstNode::Program(statements) => {
                for stmt in statements {
                    self.compile_node(stmt, output);
                }
            }
            AstNode::Call { name, args } => {
                output.push(0x01); // opcode for CALL
                output.extend_from_slice(&(name.len() as u16).to_be_bytes());
                output.extend_from_slice(name.as_bytes());
                output.push(args.len() as u8);
                for arg in args {
                    self.compile_node(arg, output);
                }
            }
            AstNode::Identifier(name) => {
                output.push(0x02); // opcode for IDENTIFIER
                output.extend_from_slice(&(name.len() as u16).to_be_bytes());
                output.extend_from_slice(name.as_bytes());
            }
            AstNode::StringLiteral(value) => {
                output.push(0x03); // opcode for STRING_LITERAL
                output.extend_from_slice(&(value.len() as u16).to_be_bytes());
                output.extend_from_slice(value.as_bytes());
            }
            AstNode::Number(num) => {
                output.push(0x04); // opcode for NUMBER
                output.extend_from_slice(&num.to_be_bytes());
            }
            _ => {
                // For brevity, other nodes not implemented yet
            }
        }
    }
}

// Test example usage:

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_lexer_and_parser() {
        let code = r#"start "photo-organizer"
filter all images with blurred faces
send results to private gallery called "memories""#;

        let mut lexer = Lexer::new(code);
        let mut parser = Parser::new(&mut lexer);
        let ast = parser.parse_program();

        assert!(matches!(ast, AstNode::Program(_)));
    }

    #[test]
    fn test_compiler_bytecode() {
        let code = r#"start "photo-organizer""#;
        let mut lexer = Lexer::new(code);
        let mut parser = Parser::new(&mut lexer);
        let ast = parser.parse_program();

        let mut compiler = Compiler::new();
        let bytecode = compiler.compile(&ast);

        assert!(!bytecode.is_empty());
    }
}
